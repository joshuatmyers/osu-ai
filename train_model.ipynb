{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5251b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "     ------------------------------------ 266.3/266.3 MB 932.0 kB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     -------------------------------------- 439.2/439.2 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.5.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.50.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, opt-einsum, keras, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-22.10.26 gast-0.4.0 google-pasta-0.2.0 h5py-3.7.0 keras-2.11.0 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\joshua\\anaconda3\\envs\\osu-ai\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c26e2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow as keras\n",
    "from keras import Model, layers\n",
    "from keras.layers import *\n",
    "from fastai.vision.all import *\n",
    "#from utils.getScreen import grab_screen\n",
    "from PIL import Image \n",
    "from PIL.ImageDraw import Draw\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6955e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv_file = 'data.csv'\n",
    "training_image_dir = 'C:/Users/Joshua/Desktop/Data/osu-ai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acef6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_records = pd.read_csv(training_csv_file)\n",
    "train_image_path = os.path.join(os.getcwd(), training_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f8b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eb3c5cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.49 MiB for an array with shape (600, 800, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m train_image_fullpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_image_path, filename)\n\u001b[0;32m      6\u001b[0m train_img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_img(train_image_fullpath, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m800\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m train_img_arr \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m train_images\u001b[38;5;241m.\u001b[39mappend(train_img_arr)\n\u001b[0;32m     10\u001b[0m train_targets\u001b[38;5;241m.\u001b[39mappend((x, y))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\osu-ai\\lib\\site-packages\\keras\\utils\\image_utils.py:324\u001b[0m, in \u001b[0;36mimg_to_array\u001b[1;34m(img, data_format, dtype)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown data_format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Numpy array x has format (height, width, channel)\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# or (channel, height, width)\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# but original PIL image has format (width, height, channel)\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.49 MiB for an array with shape (600, 800, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "for index, row in training_image_records.iterrows():\n",
    "\n",
    "    (filename, x, y) = row\n",
    "\n",
    "    train_image_fullpath = os.path.join(train_image_path, filename)\n",
    "    train_img = tf.keras.utils.load_img(train_image_fullpath, target_size=(600, 800))\n",
    "    train_img_arr = tf.keras.utils.img_to_array(train_img)\n",
    "\n",
    "    train_images.append(train_img_arr)\n",
    "    train_targets.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_targets = np.array(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = np.array(validation_images)\n",
    "validation_targets = np.array(validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 800\n",
    "height = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the common input layer\n",
    "input_shape = (height, width, 3)\n",
    "input_layer = tf.keras.layers.Input(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32858ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.layers' has no attribute 'experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#create the base layers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m base_layers \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbl_1\u001b[39m\u001b[38;5;124m'\u001b[39m)(input_layer)\n\u001b[0;32m      3\u001b[0m base_layers \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbl_2\u001b[39m\u001b[38;5;124m'\u001b[39m)(base_layers)\n\u001b[0;32m      4\u001b[0m base_layers \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbl_3\u001b[39m\u001b[38;5;124m'\u001b[39m)(base_layers)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.layers' has no attribute 'experimental'"
     ]
    }
   ],
   "source": [
    "#create the base layers\n",
    "base_layers = layers.experimental.preprocessing.Rescaling(1./255, name='bl_1')(input_layer)\n",
    "base_layers = layers.Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_3')(base_layers)\n",
    "base_layers = layers.Conv2D(32, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_5')(base_layers)\n",
    "base_layers = layers.Conv2D(64, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "base_layers = layers.MaxPooling2D(name='bl_7')(base_layers)\n",
    "base_layers = layers.Flatten(name='bl_8')(base_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb02b56a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#create the localiser branch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m locator_branch \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_1\u001b[39m\u001b[38;5;124m'\u001b[39m)(\u001b[43mbase_layers\u001b[49m)\n\u001b[0;32m      3\u001b[0m locator_branch \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_2\u001b[39m\u001b[38;5;124m'\u001b[39m)(locator_branch)\n\u001b[0;32m      4\u001b[0m locator_branch \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbb_3\u001b[39m\u001b[38;5;124m'\u001b[39m)(locator_branch)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_layers' is not defined"
     ]
    }
   ],
   "source": [
    "#create the localiser branch\n",
    "locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88ed2f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(\u001b[43minput_layer\u001b[49m, outputs\u001b[38;5;241m=\u001b[39m[locator_branch])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_layer' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(input_layer, outputs=[locator_branch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"bb_head\":tf.keras.losses.MSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses, optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTargets = {\n",
    "    \"bb_head\": train_targets\n",
    "}\n",
    "validationTargets = {\n",
    "    \"bb_head\": validation_targets\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, trainTargets,\n",
    "             validation_data=(validation_images, validationTargets),\n",
    "             batch_size=4,\n",
    "             epochs=20,\n",
    "             shuffle=True,\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.name.startswith('bl_'):\n",
    "        layer.trainable = False\n",
    "        \n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith('bb_'):\n",
    "        layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
